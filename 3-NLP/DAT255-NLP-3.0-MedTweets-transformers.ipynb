{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "691d5ef9-f9b2-4435-b753-6e49628cd480",
   "metadata": {},
   "source": [
    "ASL, v.0902323"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9579e4dd-b2a3-4928-b913-552a972ccbd4",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550462f0-c14f-41bd-8e0c-05178529382a",
   "metadata": {},
   "source": [
    "In this notebook, we use Transformers on the same task as in the previous notebook (`DAT255-NLP-2.0-MedTweets-fastai-ULMFiT.ipynb`)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b865c9-4f82-4aae-b596-a7c9ed6e9d0e",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2e265cca-ad9e-4099-9540-10cbbf5f852d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a quick check of whether the notebook is currently running on Google Colaboratory\n",
    "# or on Kaggle, as that makes some difference for the code below.\n",
    "# We'll do this in every notebook of the course.\n",
    "try:\n",
    "    import colab\n",
    "    colab=True\n",
    "except:\n",
    "    colab=False\n",
    "\n",
    "import os\n",
    "kaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b4359823-c8e1-42be-8bd8-f1c1ccd477c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np, pandas as pd, matplotlib.pyplot as plt\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6abe9203-2af9-4ab1-adf4-7f30fade157b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#import os\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = \"0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9cb89e7-e7c8-4be7-9f5f-0a6a1777db72",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (colab or kaggle):\n",
    "    !pip install transformers datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2fcc4e5d-b45a-4be0-a4f0-fff3d4c4f269",
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/gdrive\")\n",
    "    DATA = Path(\"/content/gdrive/MyDrive/Colab Notebooks/dat255-data\")\n",
    "    DATA.mkdir(exist_ok=True)\n",
    "if not colab:\n",
    "    DATA=Path('./data')\n",
    "    DATA.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b0df86d-2e01-4ee4-a07e-deaeaa1fd197",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a05267cd-0918-419c-9dd8-1b22c5c1ed3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5af3387f-6096-42f7-af84-0e278e9515ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1ce49679",
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b8112181-8b08-45f9-b039-9c8825ca2781",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'label': 'POSITIVE', 'score': 0.9998694658279419}]\n"
     ]
    }
   ],
   "source": [
    "# Verify that the transformers library is installed and operational\n",
    "print(transformers.pipeline('sentiment-analysis')('this is great!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3f6f4d78-51c4-4616-b413-d16eaa3a2a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "from transformers import (AutoTokenizer, AutoModelForSequenceClassification, \n",
    "                          PreTrainedModel, BertModel, BertForSequenceClassification,\n",
    "                          TrainingArguments, Trainer, GPT2ForSequenceClassification, \n",
    "                          RobertaForSequenceClassification)\n",
    "\n",
    "from transformers.modeling_outputs import SequenceClassifierOutput"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b33283de-aff5-4677-8977-04503956e199",
   "metadata": {},
   "source": [
    "# MedWeb using Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c5bd54a-91ed-4905-bf08-d9191e660be2",
   "metadata": {},
   "source": [
    "Load the data as before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "138dd6ab-57ec-47fb-96d3-2f8ea31590e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Influenza</th>\n",
       "      <th>Diarrhea</th>\n",
       "      <th>Hayfever</th>\n",
       "      <th>Cough</th>\n",
       "      <th>Headache</th>\n",
       "      <th>Fever</th>\n",
       "      <th>Runnynose</th>\n",
       "      <th>Cold</th>\n",
       "      <th>labels</th>\n",
       "      <th>is_test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1en</td>\n",
       "      <td>The cold makes my whole body weak.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Cold</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2en</td>\n",
       "      <td>It's been a while since I've had allergy sympt...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Hayfever;Runnynose</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3en</td>\n",
       "      <td>I'm so feverish and out of it because of my al...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Hayfever;Fever;Runnynose</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4en</td>\n",
       "      <td>I took some medicine for my runny nose, but it...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Runnynose</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5en</td>\n",
       "      <td>I had a bad case of diarrhea when I traveled t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>sober</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID                                              Tweet  Influenza  \\\n",
       "0  1en                 The cold makes my whole body weak.          0   \n",
       "1  2en  It's been a while since I've had allergy sympt...          0   \n",
       "2  3en  I'm so feverish and out of it because of my al...          0   \n",
       "3  4en  I took some medicine for my runny nose, but it...          0   \n",
       "4  5en  I had a bad case of diarrhea when I traveled t...          0   \n",
       "\n",
       "   Diarrhea  Hayfever  Cough  Headache  Fever  Runnynose  Cold  \\\n",
       "0         0         0      0         0      0          0     1   \n",
       "1         0         1      0         0      0          1     0   \n",
       "2         0         1      0         0      1          1     0   \n",
       "3         0         0      0         0      0          1     0   \n",
       "4         0         0      0         0      0          0     0   \n",
       "\n",
       "                     labels  is_test  \n",
       "0                      Cold    False  \n",
       "1        Hayfever;Runnynose    False  \n",
       "2  Hayfever;Fever;Runnynose    False  \n",
       "3                 Runnynose    False  \n",
       "4                     sober    False  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('https://github.com/HVL-ML/DAT255/raw/main/3-NLP/data/medwebdata.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59355ecf-9ea6-43f2-b0a6-d30d69e4d7ac",
   "metadata": {},
   "source": [
    "For convenience, we combine all the labels into one vector stored under `y`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "40a28a66-35a5-40e7-8a54-037015239657",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(['is_test','labels'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fe100807-13e2-4f39-81a4-c803b9538a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['labels'] = df.apply(lambda x: [x[c] for c in df.columns[2:]], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdb83b17-8d4f-4938-b751-329a5285e532",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Tweet</th>\n",
       "      <th>Influenza</th>\n",
       "      <th>Diarrhea</th>\n",
       "      <th>Hayfever</th>\n",
       "      <th>Cough</th>\n",
       "      <th>Headache</th>\n",
       "      <th>Fever</th>\n",
       "      <th>Runnynose</th>\n",
       "      <th>Cold</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1en</td>\n",
       "      <td>The cold makes my whole body weak.</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 1]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2en</td>\n",
       "      <td>It's been a while since I've had allergy sympt...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3en</td>\n",
       "      <td>I'm so feverish and out of it because of my al...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 1, 0, 0, 1, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4en</td>\n",
       "      <td>I took some medicine for my runny nose, but it...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 1, 0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5en</td>\n",
       "      <td>I had a bad case of diarrhea when I traveled t...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>[0, 0, 0, 0, 0, 0, 0, 0]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ID                                              Tweet  Influenza  \\\n",
       "0  1en                 The cold makes my whole body weak.          0   \n",
       "1  2en  It's been a while since I've had allergy sympt...          0   \n",
       "2  3en  I'm so feverish and out of it because of my al...          0   \n",
       "3  4en  I took some medicine for my runny nose, but it...          0   \n",
       "4  5en  I had a bad case of diarrhea when I traveled t...          0   \n",
       "\n",
       "   Diarrhea  Hayfever  Cough  Headache  Fever  Runnynose  Cold  \\\n",
       "0         0         0      0         0      0          0     1   \n",
       "1         0         1      0         0      0          1     0   \n",
       "2         0         1      0         0      1          1     0   \n",
       "3         0         0      0         0      0          1     0   \n",
       "4         0         0      0         0      0          0     0   \n",
       "\n",
       "                     labels  \n",
       "0  [0, 0, 0, 0, 0, 0, 0, 1]  \n",
       "1  [0, 0, 1, 0, 0, 0, 1, 0]  \n",
       "2  [0, 0, 1, 0, 0, 1, 1, 0]  \n",
       "3  [0, 0, 0, 0, 0, 0, 1, 0]  \n",
       "4  [0, 0, 0, 0, 0, 0, 0, 0]  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98f064f2-05ab-49fd-bffe-c38557a85bf2",
   "metadata": {},
   "source": [
    "Set up the transformers model. There are multiple possible models to try (at the time of writing, HuggingFace has 146,394 models in its library). \n",
    "\n",
    "One interesting option is the [PubMedBERT model](https://huggingface.co/microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract) created by Microsoft Research by training a BERT model on 14 million abstracts of PubMed articles. Have a look at the blog post [Domain-specific language model pretraining for biomedical natural language processing](https://www.microsoft.com/en-us/research/blog/domain-specific-language-model-pretraining-for-biomedical-natural-language-processing/) and the accompanying paper. \n",
    "\n",
    "A related model is the BioMed-RoBERTa model from AllenAI: https://huggingface.co/allenai/biomed_roberta_base. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64796a7",
   "metadata": {},
   "source": [
    "The more recent GPT models are also interesting options (for example the BioMedLM model from Stanford CRFM: https://huggingface.c/stanford-crfm/BioMedLM). Unfortunately, GPT models require enormous amounts of computing resources compared to many alternatives. See the end of the notebook for an example run of the GPT-2 model BioMedLM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b2aa595b-af89-414f-a393-bd4947c1946f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/biomed_roberta_base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at allenai/biomed_roberta_base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "#model_name = 'microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract'\n",
    "#model_name = \"microsoft/BiomedNLP-PubMedBERT-base-uncased-abstract-fulltext\"\n",
    "\n",
    "model_name = \"allenai/biomed_roberta_base\"\n",
    "\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf01dda1-4107-452f-97bf-e48d420d90cf",
   "metadata": {},
   "source": [
    "We need to tokenize the data in the same way as was done for the original dataset and create a data set compatible with HuggingFace:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a2769602-4e6d-411c-b55b-89eb70134b50",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = transformers.AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2eb6b03c-d5e7-405b-a6bf-cf8e293d0441",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = Dataset.from_pandas(df, split='train').train_test_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2113adc5-ec52-4b88-9d63-1ff9bb974725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['ID', 'Tweet', 'Influenza', 'Diarrhea', 'Hayfever', 'Cough', 'Headache', 'Fever', 'Runnynose', 'Cold', 'labels'],\n",
       "        num_rows: 1920\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['ID', 'Tweet', 'Influenza', 'Diarrhea', 'Hayfever', 'Cough', 'Headache', 'Fever', 'Runnynose', 'Cold', 'labels'],\n",
       "        num_rows: 640\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f4e2aeb9-4923-40bf-82cb-2c1e97c758b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID': '889en',\n",
       " 'Tweet': \"My brother says he has the flu, and he's been vomitting since last night.\",\n",
       " 'Influenza': 0,\n",
       " 'Diarrhea': 0,\n",
       " 'Hayfever': 0,\n",
       " 'Cough': 0,\n",
       " 'Headache': 0,\n",
       " 'Fever': 0,\n",
       " 'Runnynose': 0,\n",
       " 'Cold': 0,\n",
       " 'labels': [0, 0, 0, 0, 0, 0, 0, 0]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f1edf869-145a-4d80-9c49-dc32e056e343",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_encode(examples):\n",
    "    return tokenizer(examples[\"Tweet\"], truncation=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4497d345-b66d-4f66-a9e1-d9bd6c04f968",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1920 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/640 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cols = ds['train'].column_names\n",
    "cols.remove('labels')\n",
    "ds_enc = ds.map(tokenize_and_encode, batched=True, remove_columns=cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "47e36eec-4ba5-426d-b644-41ae6bdd0d1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 1920\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['labels', 'input_ids', 'attention_mask'],\n",
       "        num_rows: 640\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c5c56184-15e0-4593-b811-5d7256222682",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'allenai/biomed_roberta_base'"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7cc33f4b-19b6-4b1a-b6ce-38932fc79a1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assuming a RoBERTa model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at allenai/biomed_roberta_base were not used when initializing RobertaForSequenceClassification: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight', 'lm_head.decoder.weight', 'lm_head.layer_norm.bias', 'lm_head.dense.bias', 'lm_head.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at allenai/biomed_roberta_base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "num_labels=8\n",
    "\n",
    "if \"roberta\" not in model_name:\n",
    "    print(\"Assuming a BERT model\")\n",
    "    model = BertForSequenceClassification.from_pretrained(model_name, \n",
    "                                                        problem_type=\"multi_label_classification\", \n",
    "                                                        num_labels=num_labels)\n",
    "\n",
    "elif \"roberta\" in model_name:\n",
    "    print(\"Assuming a RoBERTa model\")\n",
    "    model = RobertaForSequenceClassification.from_pretrained(model_name, \n",
    "                                                        problem_type=\"multi_label_classification\", \n",
    "                                                        num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d95bf238-5e42-4380-abe0-dc694017155f",
   "metadata": {},
   "source": [
    "We define some metrics to use when scoring on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "84c19021-aab7-4fc7-b7b0-945b1ebfc219",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "def accuracy_thresh(y_pred, y_true, thresh=0.5, sigmoid=True): \n",
    "    y_pred = torch.from_numpy(y_pred)\n",
    "    y_true = torch.from_numpy(y_true)\n",
    "    if sigmoid: \n",
    "        y_pred = y_pred.sigmoid()\n",
    "    return ((y_pred>thresh)==y_true.bool()).float().mean().item()\n",
    "\n",
    "def f1score_thresh(y_pred, y_true, average='micro',thresh=0.5, sigmoid=True): \n",
    "    y_pred = torch.from_numpy(y_pred)\n",
    "    y_true = torch.from_numpy(y_true)\n",
    "    if sigmoid: \n",
    "        y_pred = y_pred.sigmoid()\n",
    "    return f1_score(y_true, y_pred>thresh, average=average)\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    predictions, labels = eval_pred\n",
    "    return {'accuracy_thresh': accuracy_thresh(predictions, labels),\n",
    "           'f1score_micro_thresh': f1score_thresh(predictions, labels, average='micro'),\n",
    "           'f1score_macro_thresh': f1score_thresh(predictions, labels, average='macro')}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b578303e-dfdf-457f-91a9-dc38741313b9",
   "metadata": {},
   "source": [
    "..and then the training setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fe88e2a3-34f8-4a26-819f-091eade0e352",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "num_train_epochs = 6\n",
    "\n",
    "args = TrainingArguments(\n",
    "    output_dir=\".\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    logging_steps=50,\n",
    "    weight_decay=0.01, \n",
    "    save_steps=2000\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04674d2-5d44-461f-890c-ebf58d2e1f4a",
   "metadata": {},
   "source": [
    "We have to modify the loss function to deal with multilabel problems. Here's a way to do it (from https://discuss.huggingface.co/t/fine-tune-for-multiclass-or-multilabel-multiclass/4035/9):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c72343b0-ccbe-4f9c-a8eb-0a49e613b429",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultilabelTrainer(Trainer):\n",
    "    def compute_loss(self, model, inputs, return_outputs=False):\n",
    "        labels = inputs.pop(\"labels\")\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        loss_fct = torch.nn.BCEWithLogitsLoss()\n",
    "        loss = loss_fct(logits.view(-1, self.model.config.num_labels), \n",
    "                        labels.float().view(-1, self.model.config.num_labels))\n",
    "        return (loss, outputs) if return_outputs else loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0f1039ee-abe0-42d9-bf9a-fa440f1859c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MultilabelTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=ds_enc[\"train\"],\n",
    "    eval_dataset=ds_enc[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7e46042-53d8-4c77-87b2-c22df00cc963",
   "metadata": {},
   "source": [
    "Let's see how the model does without any training on the MedWeb data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9f3ceeb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 640\n",
      "  Batch size = 8\n",
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='160' max='80' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [80/80 00:21]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'eval_loss': 0.6963170766830444,\n",
       " 'eval_accuracy_thresh': 0.6019531488418579,\n",
       " 'eval_f1score_micro_thresh': 0.20203602192638997,\n",
       " 'eval_f1score_macro_thresh': 0.20203602192638997,\n",
       " 'eval_runtime': 2.0412,\n",
       " 'eval_samples_per_second': 313.538,\n",
       " 'eval_steps_per_second': 39.192}"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa62db2-5379-40ad-b9d7-c4a22abbf46f",
   "metadata": {},
   "source": [
    "Then fine-tune it:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "385f8a8f-4987-44bc-826f-7ad4412c76cb",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/huggingface/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1920\n",
      "  Num Epochs = 6\n",
      "  Instantaneous batch size per device = 8\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 8\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1440\n",
      "  Number of trainable parameters = 124651784\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1440' max='1440' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1440/1440 01:51, Epoch 6/6]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Thresh</th>\n",
       "      <th>F1score Micro Thresh</th>\n",
       "      <th>F1score Macro Thresh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.207000</td>\n",
       "      <td>0.155405</td>\n",
       "      <td>0.958984</td>\n",
       "      <td>0.839204</td>\n",
       "      <td>0.839204</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.107800</td>\n",
       "      <td>0.103482</td>\n",
       "      <td>0.973828</td>\n",
       "      <td>0.892971</td>\n",
       "      <td>0.892971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.078000</td>\n",
       "      <td>0.094105</td>\n",
       "      <td>0.974609</td>\n",
       "      <td>0.897959</td>\n",
       "      <td>0.897959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.055800</td>\n",
       "      <td>0.090626</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>0.899213</td>\n",
       "      <td>0.899213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.044600</td>\n",
       "      <td>0.091549</td>\n",
       "      <td>0.975586</td>\n",
       "      <td>0.900557</td>\n",
       "      <td>0.900557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.043100</td>\n",
       "      <td>0.089094</td>\n",
       "      <td>0.975781</td>\n",
       "      <td>0.901743</td>\n",
       "      <td>0.901743</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 640\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 640\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 640\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 640\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 640\n",
      "  Batch size = 8\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 640\n",
      "  Batch size = 8\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=1440, training_loss=0.1102306067943573, metrics={'train_runtime': 112.0431, 'train_samples_per_second': 102.818, 'train_steps_per_second': 12.852, 'total_flos': 176733816303744.0, 'train_loss': 0.1102306067943573, 'epoch': 6.0})"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03daf6a6-36c0-483c-916e-945f377c1644",
   "metadata": {
    "tags": []
   },
   "source": [
    "## How does it compare to other approaches?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3719a508-8072-4871-b95f-0a1a885ccc94",
   "metadata": {},
   "source": [
    "From the [original article](https://www.jmir.org/2019/2/e12783/) from 2019 that presented the data set:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c211c3-bb8c-4bb5-978e-10f2eabc78a5",
   "metadata": {},
   "source": [
    "<img src=\"https://github.com/MMIV-ML/ELMED219-2022/raw/main/Lab2-NLP/assets/medweb_results.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6de2dd2-06c3-49c8-9f63-bf8e4e154122",
   "metadata": {},
   "source": [
    "The \"NAIST-en\" models are _\"ensembles of hierarchical attention network and deep character-level convolutional neural network with loss functions (negative loss function, hinge, and hinge squared)\"_. I.e. also deep learning-based models."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b6cdc8",
   "metadata": {},
   "source": [
    "> **Your turn!** What about trying an ensemble of BERT or RoBERTa models? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0e9e4b",
   "metadata": {},
   "source": [
    "# Extra: using a GPT-2 model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d42c73d8",
   "metadata": {},
   "source": [
    "> The following computations were done on a more powerful computer, equipped with an NVIDIA RTX A6000, 48GB GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f722980",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at stanford-crfm/BioMedLM were not used when initializing GPT2ForSequenceClassification: ['lm_head.weight']\n",
      "- This IS expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing GPT2ForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at stanford-crfm/BioMedLM and are newly initialized: ['score.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model_name = \"stanford-crfm/BioMedLM\" # This is a GPT2 model\n",
    "model = transformers.AutoModelForSequenceClassification.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "90d3c37b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPT2\n",
    "tokenizer.pad_token = tokenizer.eos_token"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "788ab300",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = GPT2ForSequenceClassification.from_pretrained(model_name, \n",
    "                                                        problem_type=\"multi_label_classification\", \n",
    "                                                        num_labels=num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "52447361",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.config.pad_token_id = model.config.eos_token_id\n",
    "model.config.pad_token_id = tokenizer.pad_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5a9212",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "num_train_epochs = 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7f3bbed",
   "metadata": {},
   "outputs": [],
   "source": [
    "args = TrainingArguments(\n",
    "    output_dir=\".\",\n",
    "    evaluation_strategy = \"epoch\",\n",
    "    learning_rate=2e-5,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_train_epochs,\n",
    "    logging_steps=50,\n",
    "    weight_decay=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67b2c068",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = MultilabelTrainer(\n",
    "    model,\n",
    "    args,\n",
    "    train_dataset=ds_enc[\"train\"],\n",
    "    eval_dataset=ds_enc[\"test\"],\n",
    "    compute_metrics=compute_metrics,\n",
    "    tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4eb8c01f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/alex/anaconda3/envs/huggingface/lib/python3.9/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n",
      "***** Running training *****\n",
      "  Num examples = 1920\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 1\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 1\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 3840\n",
      "  Number of trainable parameters = 2594268160\n",
      "You're using a GPT2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3840' max='3840' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [3840/3840 33:34, Epoch 2/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy Thresh</th>\n",
       "      <th>F1score Micro Thresh</th>\n",
       "      <th>F1score Macro Thresh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.139600</td>\n",
       "      <td>0.256822</td>\n",
       "      <td>0.951563</td>\n",
       "      <td>0.797054</td>\n",
       "      <td>0.797054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.164600</td>\n",
       "      <td>0.163555</td>\n",
       "      <td>0.966211</td>\n",
       "      <td>0.865579</td>\n",
       "      <td>0.865579</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to ./checkpoint-500\n",
      "Configuration saved in ./checkpoint-500/config.json\n",
      "The model is bigger than the maximum size per checkpoint (10GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./checkpoint-500/pytorch_model.bin.index.json.\n",
      "tokenizer config file saved in ./checkpoint-500/tokenizer_config.json\n",
      "Special tokens file saved in ./checkpoint-500/special_tokens_map.json\n",
      "Saving model checkpoint to ./checkpoint-1000\n",
      "Configuration saved in ./checkpoint-1000/config.json\n",
      "The model is bigger than the maximum size per checkpoint (10GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./checkpoint-1000/pytorch_model.bin.index.json.\n",
      "tokenizer config file saved in ./checkpoint-1000/tokenizer_config.json\n",
      "Special tokens file saved in ./checkpoint-1000/special_tokens_map.json\n",
      "Saving model checkpoint to ./checkpoint-1500\n",
      "Configuration saved in ./checkpoint-1500/config.json\n",
      "The model is bigger than the maximum size per checkpoint (10GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./checkpoint-1500/pytorch_model.bin.index.json.\n",
      "tokenizer config file saved in ./checkpoint-1500/tokenizer_config.json\n",
      "Special tokens file saved in ./checkpoint-1500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 640\n",
      "  Batch size = 1\n",
      "Saving model checkpoint to ./checkpoint-2000\n",
      "Configuration saved in ./checkpoint-2000/config.json\n",
      "The model is bigger than the maximum size per checkpoint (10GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./checkpoint-2000/pytorch_model.bin.index.json.\n",
      "tokenizer config file saved in ./checkpoint-2000/tokenizer_config.json\n",
      "Special tokens file saved in ./checkpoint-2000/special_tokens_map.json\n",
      "Saving model checkpoint to ./checkpoint-2500\n",
      "Configuration saved in ./checkpoint-2500/config.json\n",
      "The model is bigger than the maximum size per checkpoint (10GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./checkpoint-2500/pytorch_model.bin.index.json.\n",
      "tokenizer config file saved in ./checkpoint-2500/tokenizer_config.json\n",
      "Special tokens file saved in ./checkpoint-2500/special_tokens_map.json\n",
      "Saving model checkpoint to ./checkpoint-3000\n",
      "Configuration saved in ./checkpoint-3000/config.json\n",
      "The model is bigger than the maximum size per checkpoint (10GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./checkpoint-3000/pytorch_model.bin.index.json.\n",
      "tokenizer config file saved in ./checkpoint-3000/tokenizer_config.json\n",
      "Special tokens file saved in ./checkpoint-3000/special_tokens_map.json\n",
      "Saving model checkpoint to ./checkpoint-3500\n",
      "Configuration saved in ./checkpoint-3500/config.json\n",
      "The model is bigger than the maximum size per checkpoint (10GB) and is going to be split in 2 checkpoint shards. You can find where each parameters has been saved in the index located at ./checkpoint-3500/pytorch_model.bin.index.json.\n",
      "tokenizer config file saved in ./checkpoint-3500/tokenizer_config.json\n",
      "Special tokens file saved in ./checkpoint-3500/special_tokens_map.json\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 640\n",
      "  Batch size = 1\n",
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=3840, training_loss=0.2673093371093273, metrics={'train_runtime': 2015.1392, 'train_samples_per_second': 1.906, 'train_steps_per_second': 1.906, 'total_flos': 1032739377500160.0, 'train_loss': 0.2673093371093273, 'epoch': 2.0})"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPT2\n",
    "trainer.train()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:huggingface]",
   "language": "python",
   "name": "conda-env-huggingface-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
