{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b739f4f3",
   "metadata": {},
   "source": [
    "A.S. Lundervold, version 14.01.23"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a08b1763-9f78-4473-a8c7-14f7afecb318",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e307adfb-7c39-4ad0-ba5b-aeec92cd5731",
   "metadata": {},
   "source": [
    "In the previous notebook, we trained a model to classify fruit and exported it together with the pre-processing pipeline. \n",
    "\n",
    "In this notebook, we'll deploy the model using a (super) simple interface constructed using Gradio."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccf63db-cf4e-430a-a5a0-4f49a73f0e6e",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "26c1b9d3-4803-4ed9-b9e8-c4bc3b7d95e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a quick check of whether the notebook is currently running on Google Colaboratory\n",
    "# or on Kaggle, as that makes some difference for the code below.\n",
    "try:\n",
    "    import colab\n",
    "    colab=True\n",
    "except:\n",
    "    colab=False\n",
    "\n",
    "import os\n",
    "kaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ae8a3eb3-3a0c-484f-9245-6bb6ef235306",
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab:\n",
    "    !pip install -Uqq fastbook\n",
    "    import fastbook\n",
    "    fastbook.setup_book()\n",
    "    from fastbook import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e78e17ea-bab5-4314-8cd3-f69e51114ee4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c43c7a2-eeae-4d4f-a50b-411e9a400cdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "if colab:\n",
    "    from google.colab import drive\n",
    "    drive.mount(\"/content/gdrive\")\n",
    "    DATA = Path('/content/gdrive/MyDrive/DAT255/fruits-360')\n",
    "    DATA.mkdir(exist_ok=True, parents=True)\n",
    "    \n",
    "elif kaggle:\n",
    "    # The data is already available on Kaggle and can be added \n",
    "    # to the notebook using \"+ Add Data\".\n",
    "    DATA = Path('/kaggle/input/fruits')\n",
    "\n",
    "else:\n",
    "    # Local installation\n",
    "    # Set this to where you want to download the image data\n",
    "    NB_DIR = Path.cwd()       # Set NB_DIR to be the current working directory\n",
    "    #DATA = NB_DIR/'data'      # The data dir is the subdirectory 'data' under NB_DIR\n",
    "    DATA = Path(\"/home/ubuntu/data-tmp/fruits-360\")\n",
    "\n",
    "    DATA.mkdir(exist_ok=True) # Create the data directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c1a82eee-2d81-4ee9-bbe4-7efe86732686",
   "metadata": {},
   "outputs": [],
   "source": [
    "NB_DIR = Path.cwd()\n",
    "MODELS = NB_DIR/'..'/'models'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8408f7f1-a502-4f91-ba71-92dea80dfb9f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Load pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66700660-12b6-41f9-8429-7fae0eca9fe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = load_learner(MODELS/'fruit_model_v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5582d8a7-b28e-40c9-93d7-19fb21ae073b",
   "metadata": {},
   "source": [
    "# Use it on new images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d79cf174",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_image(img):\n",
    "    pred, idx, probs = learn.predict(img)\n",
    "    return {pred: float(probs.max())}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c8d44f61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4cd96546",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = gr.components.Image(shape=(100,100))\n",
    "label = gr.components.Label()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aeeda22a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "Running on public URL: https://eee6c4fb-9e6c-4a51.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades (NEW!), check out Spaces: https://huggingface.co/spaces\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"https://eee6c4fb-9e6c-4a51.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.Interface(fn=classify_image, inputs=image, outputs=label).launch(share=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46dd2753-b134-4383-bdf5-0d048646cb3a",
   "metadata": {},
   "source": [
    "> What happens as you try to upload other pictures? For example, pictures of fruits where the background isn't deleted? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07a5bf0c-b94d-4ebf-bf8b-38a75b62ad69",
   "metadata": {},
   "source": [
    "You'll see that the application only works on simple pictures of single fruits from the classes represented in the data set and basically only on pictures with no background."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c45f986-5da8-4c52-a3dc-a5e003d3e25f",
   "metadata": {},
   "source": [
    "> <span style=\"color:green\">It's crucial to know what kind of data the model is trained on and to make sure you're not using it in situations significantly different from what's reflected in the training data. </span>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21cf3baf",
   "metadata": {},
   "source": [
    "> <span style=\"color:green\">In this case, all the pictures of fruit used during training (and during model evaluation!) were of dimension 100x100, recorded by a specific kind of camera, in a specific setting, and preprocessed by removing the background in a specific way. If we're to create an app using only this data set, we'd have to incorporate this somehow. Feel free to think of ways to try to overcome the issue. For example, removing the background, expanding the data set by inserting various backgrounds into existing images, obtaining more data, etc. </span> \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf3ed6e",
   "metadata": {},
   "source": [
    "> <span style=\"color:green\"> Such issues lead to an essential lesson in machine learning: make sure that your model evaluation setup includes test data that give a good representation of the kind of data the model will meet when deployed! Much more about this issue later in the course.</span>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fastai",
   "language": "python",
   "name": "fastai"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
