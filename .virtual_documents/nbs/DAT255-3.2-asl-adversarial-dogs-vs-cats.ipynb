














# This is a quick check of whether the notebook is currently running on Kaggle, 
# as that makes some difference for the code below.
# We'll do this in every notebook of the course.
import os
kaggle = os.environ.get('KAGGLE_KERNEL_RUN_TYPE', '')


from fastai.vision.all import *


import timm


from fastai.imports import *
NB_DIR = Path.cwd()








path = untar_data(URLs.DOGS)


path.ls()








sz=224
item_tfms = Resize(sz)
batch_tfms = None
bs=64


dls = ImageDataLoaders.from_folder(path, train='train', valid='valid', 
            item_tfms=item_tfms, batch_tfms=batch_tfms, bs=bs)


dls.show_batch()





#model = 'convnext_small_in22ft1k'
model = resnet18


learn = vision_learner(dls, model, pretrained=True, metrics=accuracy)


lr = learn.lr_find(suggest_funcs=(minimum, steep, valley), show_plot=False)
base_lr = (lr.valley + lr.steep)/2
print(base_lr)


learn.fine_tune(1, base_lr=base_lr)





interp = ClassificationInterpretation.from_learner(learn)


interp.plot_top_losses(6)


interp.plot_confusion_matrix()





if kaggle: 
    model_dir = Path('/kaggle/working/models/')
    model_dir.mkdir(exist_ok=True)
    learn.export(model_dir/'catsdogs_model.pkl')
else:
    learn.export('catsdogs_model.pkl')























if kaggle: 
    learn = load_learner('/kaggle/working/models/catsdogs_model.pkl')
else:
    learn = load_learner(path/'catsdogs_model.pkl')


learn.training


#learn.model.eval()














example_image_fn = path/'valid'/'cats'/'cat.3835.jpg'
example_image = PILImage.create(example_image_fn)
example_image





import torchvision.transforms as T


example_image = example_image.resize((sz,sz))


example_image_t = T.ToTensor()(example_image)


example_image_t.shape


plt.imshow(example_image_t.permute(1,2,0).numpy())





# **Setting requires_grad_ to True is crucial for tracking gradients**
# This tells PyTorch to keep track of any computations performed on this tensor
# so we can calculate gradients needed for the adversarial attack.
example_image_t= example_image_t.requires_grad_(True)





example_image_output = learn.model(example_image_t[None])





example_image_output





example_image_output = F.softmax(example_image_output, dim=-1)
example_image_output





example_image_predicted_label = torch.argmax(example_image_output)

print(learn.dls.vocab[example_image_predicted_label])





loss = learn.loss_func(example_image_output, example_image_predicted_label)
print(loss)





learn.zero_grad()
loss.backward()





# **Access the calculated gradients for the input image**
# These gradients are essential for the FSGM attack. PyTorch stored them 
# since we set requires_grad_ to True for our image tensor.
image_grad = example_image_t.grad.data
print(image_grad.shape)


image_grad[0,:3,:3]








sign_image_grad = image_grad.sign()
print(sign_image_grad[:3,:3,:3])





epsilon = 0.01


perturbed_example_image = example_image_t + epsilon*sign_image_grad


print(perturbed_example_image[:3,:3,:3])





print(perturbed_example_image.max())


perturbed_example_image = torch.clamp(perturbed_example_image, 0, 1)


print(perturbed_example_image.max())





print(f"Original loss: {float(loss)}")


with torch.no_grad():
    new_loss = learn.loss_func(learn.model(perturbed_example_image[None]), torch.argmax(example_image_output))
    print(f"New loss: {new_loss}")





plt.imshow(perturbed_example_image.detach().cpu().permute(1, 2, 0).numpy())








perturbed_output = learn.model(perturbed_example_image[None])
print(learn.dls.vocab[torch.argmax(perturbed_output)])








diff_image = example_image_t - perturbed_example_image


diff_image.max(), diff_image.min()





plt.imshow(diff_image.detach().cpu().permute(1, 2, 0).numpy()*255)
plt.show()





diff_output = learn.model(diff_image[None])
print(learn.dls.vocab[torch.argmax(diff_output)])











# Example image gradient (shape corresponds to a single pixel)
image_gradient = torch.tensor([[0.1, 0.2, 0.3]])  

# Epsilon value controlling perturbation magnitude
epsilon = 0.05

# Original pixel value (now also a tensor for consistency)
original_pixel = torch.tensor([[0.5, 0.5, 0.5]])  

# Apply the perturbation (broadcasting will add it to each color channel)
perturbation = epsilon * image_gradient
adversarial_pixel = torch.clamp(original_pixel + perturbation, 0, 1)

print("Original pixel:", original_pixel)
print("Perturbation:", perturbation)
print("Adversarial pixel:", adversarial_pixel)







plt.imsave('perturbed_cat.png', perturbed_example_image.detach().permute(1, 2, 0).numpy())








def fgsm_attack(image, epsilon, image_grad):
    """
    Perform the Fast Gradient Sign Method (FGSM) attack on an image.

    Parameters:
    image: The original image.
    epsilon: The epsilon value used to perturb the image.
    image_grad: The gradients of the image.

    Returns:
    perturbed_image: The perturbed image.
    """
    
    # Collect the element-wise sign of the image gradient
    sign_image_grad = image_grad.sign()
    # Create the perturbed image by adjusting each pixel of the input image
    perturbed_image = image + epsilon*sign_image_grad
    # Adding clipping to maintain [0,1] range
    perturbed_image = torch.clamp(perturbed_image, 0, 1)
    # Return the perturbed image
    return perturbed_image





def perturb(learn, img_path, epsilon):
    """
    Perform an adversarial attack on an image and return the perturbed image and the predicted labels.

    Parameters:
    learn: The Learner object.
    img_path: The path to the image to be perturbed.
    epsilon: The epsilon value used to perturb the image.

    Returns:
    perturbed_image: The perturbed image.
    predicted_label: The label predicted for the original image.
    perturbed_label: The label predicted for the perturbed image.
    """

    # Perform the transformations and instruct PyTorch to track the gradients
    img_t = T.ToTensor()(PILImage.create(img_path).resize((sz,sz)))
    img_t = img_t.requires_grad_(True)

    output = learn.model(img_t[None])

    # Here's the prediction before the attack
    predicted_label = torch.argmax(output)

    # Perform the attack
    loss = learn.loss_func(output, predicted_label)
    learn.zero_grad()
    loss.backward()
    img_t_grad = img_t.grad.data
    perturbed_image = fgsm_attack(img_t, epsilon, img_t_grad)

    # Here's the prediction after the attack
    perturbed_output = learn.model(perturbed_image[None])
    perturbed_label = torch.argmax(perturbed_output)
    # The difference between input and output
    diff_image = img_t - perturbed_image

    # We need to convert the image back to numpy for plotting
    perturbed_image = perturbed_image.detach().cpu().permute(1, 2, 0).numpy()
    diff_image = diff_image.detach().cpu().permute(1, 2, 0).numpy()*255
    
    return perturbed_image, learn.dls.vocab[predicted_label], learn.dls.vocab[perturbed_label], diff_image



def show_perturbed_img(original_image, predicted_label, perturbed_image, perturbed_label, diff_image, epsilon):
    """
    Display an original image and its perturbed version side by side.

    Parameters:
    original_image: The original image.
    predicted_label: The label predicted for the original image.
    perturbed_image: The perturbed image.
    perturbed_label: The label predicted for the perturbed image.
    epsilon: The epsilon value used to perturb the image.
    """
    
    f, ax = plt.subplots(1,3, figsize=(14,10))

    ax[0].imshow(PILImage.create(original_image).resize((sz,sz)))
    ax[0].axis('off')
    ax[0].set_title(f"Original image. Label: {predicted_label}")

    ax[1].imshow(perturbed_image)
    ax[1].axis('off')
    ax[1].set_title(f"Perturbed image. Label: {perturbed_label}; Epsilon: {epsilon}")

    ax[2].imshow(diff_image*255)
    ax[2].axis('off')
    ax[2].set_title(f"Difference (scaled)")
    

    plt.show()


epsilon=0.002


for test_img in random.choices(dls.valid_ds.items, k=5):
    perturbed_image, predicted_label, perturbed_label, diff_image = perturb(learn, test_img, epsilon)
    show_perturbed_img(test_img, predicted_label, perturbed_image, perturbed_label, diff_image, epsilon=epsilon)





epsilons = [0.0001, 0.0005, 0.001, 0.005]


successful_attacks = []
unsuccessful_attacks = []


n=10


for img in dls.valid_ds.items:
    # Loop over different epsilon values
    for epsilon in epsilons:
        try:
            # Perform the adversarial attack on the image
            perturbed_image, predicted_label, perturbed_label, diff_image = perturb(learn, img, epsilon)
            # If the attack was successful, add it to the list of unsuccessful attacks
            if predicted_label != perturbed_label:
                successful_attacks.append((img, predicted_label, perturbed_image, perturbed_label, diff_image, epsilon))
                break
        except Exception as e:
            print(f"Error processing image {img}: {e}")
    
    if len(successful_attacks)>=n:
        break


for img in dls.valid_ds.items:
    # Loop over different epsilon values
    for epsilon in epsilons:
        try:
            # Perform the adversarial attack on the image
            perturbed_image, predicted_label, perturbed_label, diff_image = perturb(learn, img, epsilon)
            # If the attack was unsuccessful, add it to the list of unsuccessful attacks
            if predicted_label == perturbed_label:
                unsuccessful_attacks.append((img, predicted_label, perturbed_image, perturbed_label, diff_image, epsilon))
                break
        except Exception as e:
            print(f"Error processing image {img}: {e}")
    
    if len(unsuccessful_attacks)>=n:
        break


len(successful_attacks)


for imgs in successful_attacks:
    show_perturbed_img(imgs[0], imgs[1], imgs[2], imgs[3], imgs[4], imgs[5])


for imgs in unsuccessful_attacks:
    show_perturbed_img(imgs[0], imgs[1], imgs[2], imgs[3], imgs[4], imgs[5])














# We use the cat image from https://github.com/fastai/fastbook/raw/master/images/chapter1_cat_example.jpg
!wget https://github.com/fastai/fastbook/raw/master/images/chapter1_cat_example.jpg
example_cat = 'chapter1_cat_example.jpg'


example_image = PILImage.create(example_cat)


example_image


example_image_t = T.ToTensor()(example_image.resize((sz,sz)))








class Hook():
    def __init__(self, m):
        self.hook = m.register_forward_hook(self.hook_func)   
    def hook_func(self, m, i, o): self.stored = o.detach().clone()
    def __enter__(self, *args): return self
    def __exit__(self, *args): self.hook.remove()
        
        
class HookBwd():
    def __init__(self, m):
        self.hook = m.register_backward_hook(self.hook_func)   
    def hook_func(self, m, gi, go): self.stored = go[0].detach().clone()
    def __enter__(self, *args): return self
    def __exit__(self, *args): self.hook.remove()


def get_gradcam(img_fn, cls=0):
    img = T.ToTensor()(PILImage.create(img_fn))

    dimensions = img.shape[1:]
        
    with HookBwd(learn.model[0]) as hookg:
        with Hook(learn.model[0]) as hook:
            output = learn.model.eval()(img[None])
            act = hook.stored
        output[0,cls].backward()
        grad = hookg.stored
    
    w = grad[0].mean(dim=[1,2], keepdim=True)
    cam_map = (w * act[0]).sum(0)

    x_dec = TensorImage(dls.valid.decode((img,))[0][0])
    _,ax = plt.subplots()
    x_dec.show(ctx=ax)
    ax.imshow(cam_map.detach().cpu(), alpha=0.3, extent=(0,dimensions[1],dimensions[0],0),
                interpolation='bilinear', cmap='magma')
    plt.show()


get_gradcam(example_cat, cls=0)





perturbed_cat, predicted_label, perturbed_label, diff_image = perturb(learn, example_cat, 0.01)


predicted_label, perturbed_label


plt.imsave("another_perturbed_cat.png", perturbed_cat)





get_gradcam('another_perturbed_cat.png', cls=0)


get_gradcam('another_perturbed_cat.png', cls=1)


















